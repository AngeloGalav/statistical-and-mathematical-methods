We have to minimize the function f, by finding the minimum of the function. 

This is called **uncontrained** optimization. 

1. First order condition. If x* is a point of local minimum. 


(?)

In optimization, the f function is called the objectibe funxtino, while in machine learning is called the "**loss function**", since it represent a loss that we want to minimize. 

$$f(x) = ||Ax-b||^2_2$$
The loss is given by the the [..] the parameters that i want to return and the data that I have. 

The algorithms, in optimization, are all **iterative**, since they create a sequence of appromixate solution. The solution is, in fact, a vector of solution (that is x*). Each component of the vector is a real number. 
We can associate an index to each component of the vector, which says how the sequence is create. 

Each solution xk converges to the x* for k to infinity. 
$$
x_k \longrightarrow x^*
$$

If $x_0$ is given, it is called the starting guess, or the first iteration of $x$.

$x_k$ is created by using some previous iterations of x (iterative method). 
$$x_k = G(x_{k-1})$$
Iterations can be implemented with **loops**. 

The sequence is truncated through a particular index called $k^*$. 
So in reality, I just compute the sequence $x_0, x_1 ... x_{k^*}$
This truncation, since it is an approximation, can cause an error called **truncation error**. Usually, the truncation error can be greater than the other types of error.

Let's suppose that we have $||x^* - x_{k^*}||$. I cannot know how much is this error, since we dont have $x^*$. 

So, how can I know when to stop the iteration? There are some kind of rules, called **stopping criteria**, which (in the case of approximate minimization) they consider if the point is a _minimum_ or not. 

These 2 condition seen at the start, though, (algorithm) can only find local minimums, not absolute. You cannot know if the solution is an absolute minimum, or near an absolute minimum. 

So, the stopping condition of these iterative operation is when the gradient of $f$ in iteration $k$ is small enough. The $\tau$ influnces the stopping of the function, and it depends (in a sense) to the precision that you are searching in a result. 

$$
||\nabla f(x_k)|| < \tau_1
$$

Obviously, if $\tau$ is smaller, the result is more accurate, but requires more time.  


We consider algorithms which decrease the function, so we are sure to go to a local minimum and not a local maximum. 


We also have to consider another condition:
$$
||x_{k+1} - x_k|| < \tau_2
$$


To understand why we need this second condition, we need to consider a parable. 
If the two solution are very similar to each other, we know that we are in a local minimum, since there's a 

We also have a third and final condition, which essentially guarantees that the **iteration will stop**. Essentially, it states that $k$ must be lower than a certain $k_{max}$, defined by the user. 
$$
k \le k_{max}
$$
So, the `while` loop must stop if the number of iterations reaches the maximum number of iteration.  


-----
## Descent methods

There are many classes of method, in machine learning the most famous are the **descent methods**.  

Essentially, we have a single formula which computes $x_{k+1} = x_k + \alpha_{k} P_k$
where $P_k \in R^n$ (is a vector) and $\alpha_k \in R^+$ (is a positive number).

$P_k$ is also called the **descent direction (or search direction)**, and it is a kind of the direction towards the solution. 

$\alpha _k$  is called the **step length**, since if we consider the product $\alpha_k \cdot P_k$.

$\alpha _k$ and $P_k$ are selected so that the function _always decreses_. 

$$
f(x_{k+1}) \lt f(x_k) \ k 
$$

To find $P_k$, we **derive** (facciamo una derivazione). 

So that p is a descent direction in x if $\exists \bar \alpha \gt 0$ :
$$
f(x+\alpha p) < f(x)
$$
$$
\forall \alpha \in [o, \bar \alpha]
$$

so it is possibile to find infinite points in which the function decreases in relation to $x$. 
Essentially, $p$ is a possible _descent direction_ if it lets us find a new point by which $x_{k+1}$ is decreasing in respecto to $x_k$, where $x$ is $x_k$ and $x+\alpha p$ is $x_{k+1}$.

-------
If f is continuos and differentiable in a neighbour of $x \in R^n$ and p \in R^n, $p \ne 0$, and $$p^T \cdot \nabla f(x) < 0$$ then $p$ is a _descent direction_ for $f$ in $x$ ($p$ is $P_k$).

The opposite is not necessarily true.

Based on this inequality, the method can find a value for $P_k$. 

### Basic choices for P
A basic choice of the value of P is $p = -\nabla f(x)$

So that we have

$$ -\nabla f(x)^T\nabla f(x) < 0$$

These method are called the gradient methods, in which essentially p is a gradient of the function. 
$$x_{k+1} = x_k + \alpha_k p_k$$

$$= xk - \alpha_k \nabla f(x_k)$$
So the gradient methods differ from the choice of $\alpha _k$ .


##### Convergence 
The gradient methods _do not_ converge for any choice of $\alpha _k$ .

## Choosing $\alpha _k$ 
If I consider a fixed step length, then we say that we can chose \alpha _ k in two ways :

### 1. Constant step length (or size)
This means that $\alpha_k$ is a constant, so: $$\alpha _ k = c, \forall k$$ 
So ultimately we obtain $x_{k+1} = x_k - c \nabla f(x_k)$.

In machine learning, this constant is called a **learning rate**. 
There's a threshold value of the learning rate the function converges. 
Obviously, though, if you decrease the learning rate, you need _many more iterations to reach the minimum_. 
We could visualize the leaning rate as the step in a path.

Here's a visual representation of the path. 

###### Example: contour curve
Contour curve (level) is an ellipse, so that the contour lever. 
The path goes towards the minimum. 
$$
c\in R, \{x|x\in R^2, t(x) = c\}
$$
### 2. Variable step length
To find the step length, we can use some strategies called **line search strategies**. 
Some of them are:
1. Binary line search
2. Armijo line search
3. Golden line search

The most import is the **Armijo line search**.

##### Armijo line search

For any $\alpha$ we apply the backtracking procedure. So essentially, I have to find $\alpha _k$,
So I find an $\alpha$ , which is tentative, and I set it to 1. ($\alpha = 1$). 
The value 1 is considered a big value, and I repeat until some conditions are true (the conditions are not so important).
Since I need a small value of \alpha to obtain convergence, for each value of \alpha I choose \alpha so that some condition about the function are verified. 
Usially \alpha is divided by 2, and when these conditions are verified, alpha is $\alpha_k$. 

So if \alpha_k is chosen by the Armijo backtracking rule, then I'm sure that the sequence 
$$\{x_k\}^\inf_{k=0} \longrightarrow x^*$$
converges to the solution of the problem. 

So another thing we have to consider is the convergence speed (or convergence rate).
Since we are interested to plot like these:


I prefer the method 2.

If the method convergences fast, we can assume that iteration convergences to the solution in less time. 

Essentially, the time of calculus can be seen as $k^* \cdot TIME_{it}$, 
We need to consider both the number of iteration and the time for each iteration. 
If we compare these two methods, then .

However, the convergences rate is important since in some ways the final time is proportional to it. 

An iterative method has q-convergence rate (speed) if 
$$
\dfrac{|| x_{k+1} - x_k||}{ ||x_k - x^*||^q} \lt c 
$$
which essentially means:
$$
\dfrac{|| e_{k+1}||} {||e_k||^q} \lt c 
$$